{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "En21uLwXsqpC"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chu-ise/411A-2022/blob/main/notebooks/08/01_sentiment_lexicon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk58BWF5sqpF"
      },
      "source": [
        "# Sentiment Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F72VkSSUxqeN"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install ekorpkit[model,visualize]==0.1.22.post0.dev10\n",
        "%pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0IlC7ndxn7Y"
      },
      "outputs": [],
      "source": [
        "from ekorpkit.models.metrics import evaluate_classification_performance\n",
        "from ekorpkit.visualize.classification import plot_confusion_matrix\n",
        "\n",
        "from ekorpkit import eKonf\n",
        "\n",
        "config_group='visualize/plot=confusion_matrix'\n",
        "cfg = eKonf.compose(config_group=config_group)\n",
        "cfg.display_labels = ['pos', 'neg']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZn6hyjasqpG"
      },
      "source": [
        "## Lexicon-based Sentiment Analysis\n",
        "\n",
        "### NLTK Movie Reviews Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySm6zAG-sqpG"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('movie_reviews')\n",
        "\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "print('#review count:', len(movie_reviews.fileids())) #영화 리뷰 문서의 id를 반환\n",
        "print('#samples of file ids:', movie_reviews.fileids()[:10]) #id를 10개까지만 출력\n",
        "print('#categories of reviews:', movie_reviews.categories()) # label, 즉 긍정인지 부정인지에 대한 분류\n",
        "print('#num of \"neg\" reviews:', len(movie_reviews.fileids(categories='neg'))) #label이 부정인 문서들의 id를 반환\n",
        "print('#num of \"pos\" reviews:', len(movie_reviews.fileids(categories='pos'))) #label이 긍정인 문서들의 id를 반환\n",
        "\n",
        "fileid = movie_reviews.fileids()[0] #첫번째 문서의 id를 반환\n",
        "print('#id of the first review:', fileid)\n",
        "print('#part of the first review:', movie_reviews.raw(fileid)[:500]) #첫번째 문서의 내용을 500자까지만 출력\n",
        "print('#sentiment of the first review:', movie_reviews.categories(fileid)) #첫번째 문서의 감성\n",
        "\n",
        "fileids = movie_reviews.fileids() #movie review data에서 file id를 가져옴\n",
        "reviews = [movie_reviews.raw(fileid) for fileid in fileids] #file id를 이용해 raw text file을 가져옴\n",
        "categories = [movie_reviews.categories(fileid)[0] for fileid in fileids] "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSTBRAkLsqpI"
      },
      "source": [
        "### TextBlob\n",
        "\n",
        "- https://textblob.readthedocs.io/en/dev/quickstart.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjjrYSSqsqpJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZxooIOisqpJ"
      },
      "outputs": [],
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "result = TextBlob(reviews[0])\n",
        "print(result.sentiment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNIEqjLCsqpK"
      },
      "outputs": [],
      "source": [
        "def sentiment_TextBlob(docs):\n",
        "    results = []\n",
        "\n",
        "    for doc in docs:\n",
        "        testimonial = TextBlob(doc)\n",
        "        if testimonial.sentiment.polarity > 0:\n",
        "            results.append('pos')\n",
        "        else:\n",
        "            results.append('neg')\n",
        "    return results\n",
        "\n",
        "predictions = sentiment_TextBlob(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxBAdFy6sqpK"
      },
      "outputs": [],
      "source": [
        "cm = evaluate_classification_performance(categories, predictions)\n",
        "plot_confusion_matrix(cm, **cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMhvEvYqsqpL"
      },
      "source": [
        "### AFINN\n",
        "\n",
        "- https://github.com/fnielsen/afinn \n",
        "- http://corpustext.com/reference/sentiment_afinn.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JQ7oL5ZsqpL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install afinn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFNljjCcsqpM"
      },
      "outputs": [],
      "source": [
        "from afinn import Afinn\n",
        "\n",
        "def sentiment_Afinn(docs):\n",
        "    afn = Afinn(emoticons=True)\n",
        "    results = []\n",
        "\n",
        "    for doc in docs:\n",
        "        if afn.score(doc) > 0:\n",
        "            results.append('pos')\n",
        "        else:\n",
        "            results.append('neg')\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IT2AiPVuxn7c"
      },
      "outputs": [],
      "source": [
        "predictions = sentiment_Afinn(reviews)\n",
        "cm = evaluate_classification_performance(categories, predictions)\n",
        "plot_confusion_matrix(cm, **cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfZUV32zsqpM"
      },
      "source": [
        "### VADER\n",
        "\n",
        "- https://github.com/cjhutto/vaderSentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6eHD0LVsqpM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dl2s2OETsqpM"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "def sentiment_vader(docs):\n",
        "    analyser = SentimentIntensityAnalyzer()\n",
        "    results = []\n",
        "\n",
        "    for doc in docs:\n",
        "        score = analyser.polarity_scores(doc)\n",
        "        if score['compound'] > 0:\n",
        "            results.append('pos')\n",
        "        else:\n",
        "            results.append('neg')\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-4WOWw-xn7d"
      },
      "outputs": [],
      "source": [
        "predictions = sentiment_vader(reviews)\n",
        "cm = evaluate_classification_performance(categories, predictions)\n",
        "plot_confusion_matrix(cm, **cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD6BW8ZvsqpN"
      },
      "source": [
        "## ML-based Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn95MSVmsqpN"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(reviews, categories, test_size=0.2, random_state=7)\n",
        "\n",
        "print('Train set count: ', len(X_train))\n",
        "print('Test set count: ', len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RhUJW4QsqpN"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "tfidf = TfidfVectorizer().fit(X_train) \n",
        "\n",
        "X_train_tfidf = tfidf.transform(X_train)\n",
        "print('#Train set dimension:', X_train_tfidf.shape)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "print('#Test set dimension:', X_test_tfidf.shape)\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=0.01)\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "print('#Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "print('#Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZbSkECXsqpO"
      },
      "outputs": [],
      "source": [
        "predictions = NB_clf.predict(X_test_tfidf)\n",
        "cm = evaluate_classification_performance(y_test, predictions)\n",
        "plot_confusion_matrix(cm, **cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MI0ttDPkvEz6"
      },
      "outputs": [],
      "source": [
        "name = input(\"What is your name? \")\n",
        "sid = input(\"What is your student ID? \")\n",
        "print(\"Name: \" + name + \"\\nStudent ID: \" + sid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CHPXVxj1FJ6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "01_sentiment_lexicon.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
